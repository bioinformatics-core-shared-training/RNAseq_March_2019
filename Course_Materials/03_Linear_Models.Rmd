---
title: "RNA-seq analysis in R"
author: "Oscar"
date: '`r format(Sys.time(), "Last modified: %d %b %Y")`'
output:
  html_notebook:
    toc: yes
    toc_float: yes
  html_document:
    toc: yes
    toc_float: yes
minutes: 300
layout: page
subtitle: Linear Models
bibliography: ref.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
**Original Authors: Belinda Phipson, Anna Trigos, Matt Ritchie, Maria Doyle, Harriet Dashnow, Charity Law**


Based on the course [RNAseq analysis in R](http://combine-australia.github.io/2016-05-11-RNAseq/) delivered on May 11/12th 2016

## Simulating linear models

We are going to simulate an experiment with 2 factors:

```{r pressure, echo=TRUE}
Treatment <- rep(c("Treatment A", "Control"), 3)
X <- cbind(c(1,0,1,0,1,0), c(0,1,0, 1, 0, 1))
Treatment <- factor(Treatment, levels=c("Treatment A", "Control"))
model.matrix(~Treatment)
model.matrix(~Treatment -1)

Treatment <- rep(c("Treatment A", "No Treatment"), 4)
ER <- rep(c("+", "-"), c(4,4))

```
We can obtain the design matrix for a model without and with interaction with the following commands:
```{r}
model.matrix(~Treatment + ER)
model.matrix(~Treatment * ER)
```
Now we will simulate a model without interaction. We need to provide a set of theoretical variable for our parameters, and a level of noise in our model:
```{r}
params <- c(3, 2, -4)
names(params) <- c("Intercept", "TreatA", "ER+")
noise <- 1
X <- model.matrix(~Treatment + ER)
Y <- X %*% params
errors <- rnorm(length(Y), 0, 1)
Y <- Y + errors
```
Now we can compute the estimates of our parameters: We need to use specific functions for matrix algebra, like: 
Transpose: t(X)
Multiply matrices: %*%
Inverse of a matrix: solve(X)  
```{r}
beta.pars <- solve(t(X) %*% X) %*% t(X) %*% Y
```
However, we can use the linear model function in R, lm() and inspect the results of the fit, compute confidence intervals, etc.:
```{r}
m <- lm(Y ~ Treatment + ER)
summary(m)
confint(m)
```
## Large Scale Hypothesis testing: FDR

When we are doing thousands of tests for differential expression, the overall significance level of a test is very difficult to control. Let's see why:
First, we simulate 40,000 genes not differentially expressed (with a mean of zero). We assume that we have 10 replicates of this experiment:
```{r}

N <- 40000
R <- 10
X <- matrix(rnorm(N* R, 0, 1), nrow=N)
```
Now we assume that we run a t-test under the null hypothesis that the mean is zero for each of these genes, that is each row in the matrix:
```{r}
t.test(X[1,])$p.value
pvals <- apply(X, 1, function(y) t.test(y)$p.value)
```
Because we have generated this data with mean zero, we know that none of these genes are differentially expressed, so we would like to be able to not reject any of the hypothesis. However, if you choose a significance level of 0.05 we get 
```{r}
sum(pvals<0.05)
```
Too many rejections!!!
In fact, if we look at the distributions of the p-values obtained we get:
```{r}
hist(pvals)
```


That is, if the null hypothesis is true, the p-values will follow a uniform distribution.
This is the key to all methods that aim to control the proportion of false positives amongs the genes that we call differentially expressed. Let's add 1000 genes to our set that are really differentially expressed (mean of 1):
```{r}
df <- 1000
Y <- matrix(rnorm(df* R, 1, 1), nrow=df)
Z <- rbind(X, Y)
pvals <- apply(Z, 1, function(y) t.test(y)$p.value)
```
Let's look at the distribution of p-values now:
```{r}
hist(pvals)
```


What would be the number of false positives now? How many would we expect if we reject p-values samller than our significance level, 0.05?
```{r}
exp.sig<- (nrow(Z))*0.05
obs.sig <- sum(pvals<0.05)
FDR <- exp.sig / obs.sig
FDR
```
We can compare this with the Benjamini-Hochberg method:
```{r}
pvals.adj <- p.adjust(pvals, method="BH")
plot(pvals, pvals.adj)
abline(v=0.05, col=2)
```
