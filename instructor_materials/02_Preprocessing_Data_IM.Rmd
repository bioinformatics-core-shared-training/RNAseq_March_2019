---
title: "RNA-seq analysis in R"
author: "Stephane Ballereau, Mark Dunning, Oscar Rueda, Ashley Sawle"
date: '`r format(Sys.time(), "Last modified: %d %b %Y")`'
output:
  html_notebook:
    toc: yes
  html_document:
    toc: yes
minutes: 300
layout: page
subtitle: Pre-processsing RNA-seq data
editor_options: 
  chunk_output_type: inline
---

# Introduction

* import our counts into R
* manipulate the imported data so that it is in the correct format for DESeq2
* filter out unwanted genes
* run some initial QC on the raw count data

# Data import

```{r setup, message = FALSE}
library(DESeq2)
library(tidyverse)
```

## Mouse mammary gland dataset

* basal (B) and luminal cells (L) in the mammary gland ...
* ...of virgin, pregnant and lactating mice. 
* two biological replicates.

## Reading in the sample metadata

```{r loadSampleInfo, message = FALSE}
# Read the sample information into a data frame
sampleinfo <- read.delim("data/SampleInfo.txt", stringsAsFactors=F)
sampleinfo
```

## Reading in the  count data

```{r loadData, message = FALSE}
# Read the data into R
seqdata <- read.delim("data/GSE60450_Lactation.featureCounts", 
                      comment = "#",
                      stringsAsFactors=F)
head(seqdata)
```

### A quick intro to `dplyr`

* `dplyr` [@Wickham2018] was developed to data manipulation more intuitive 
* also makes use of a new symbol `%>%` - the "pipe"

Suppose we wanted a new sample table that:

1. Just includes the "basal" samples
2. Only has the columns "CellType" and "Group"
3. Renames the "CellType" column as "Cell"

In base `R` we would do the something like:

```{r baseR, eval=FALSE}
newTable <- sampleinfo

basal <- which(newTable$CellType=="basal")
newTable <- newTable[basal, ]

newTable <- newTable[basal, c("CellType", "Group")]

colnames(newTable)[1] <- "Cell"
```

With `dplyr`:

```{r dplyr, eval=FALSE}
newTable <- sampleinfo
newTable <- filter(newTable, CellType=="basal")
newTable <- select(newTable, CellType, Group)
```

use the pipe - `%>%`:

```{r pipe, eval=FALSE}
newTable <- sampleinfo %>%
    filter(CellType=="basal") %>%
    select(CellType, Group) %>% 
    rename(Cell=CellType)
```

## Format the data

Need to reformat the counts into a suitable format for DESeq2.

Two new `dplyr` commands:

* `column_to_rownames` to set the rownames using a named column
* `rename_all` which allows to rename all the columns using a string function

```{r createCountMatrix}
countdata <- seqdata %>%
    column_to_rownames("Geneid") %>% # turn the geneid column into rownames
    rename_all(str_remove, ".bam") %>% # remove the ".bam" from the column names
    select(sampleinfo$Sample) %>% # keep sample columns using sampleinfo$Sample
    as.matrix()

head(countdata)
```


# Filtering the genes

`DESeq` does not require prefiltering - `independent filtering`
* some filtering reduces data size --> quicker, less memory
* keep all genes where rowSum greater than 5

```{r filterGenes}
dim(countdata)
keep <- rowSums(countdata) > 5
countdata <- countdata[keep,]
dim(countdata)
```

# Quality assessment

**Important** to assess the quality of our data.

## Library sizes bar plot

```{r librarySizes}
librarySizes <- colSums(countdata)
barplot(librarySizes, 
        names=names(librarySizes), 
        las=2, 
        main="Barplot of library sizes")
abline(h=20e6, lty=2)
```

## Count distribution boxplots

* Count data is not normally distributed
* Typically we use a `log2` transformation
* `log2(0)` would create errors

```{r logTransform}
# Get log2 counts per million
logcounts <- log2(countdata + 1)
```

```{r plotLogCounts}
# make a colour vector
statusCol <- as.numeric(factor(sampleinfo$Status)) + 1
# Check distributions of samples using boxplots
boxplot(logcounts, 
        xlab="", 
        ylab="Log2(Counts)",
        las=2,
        col=statusCol)
# Let's add a blue horizontal line that corresponds to the median logCPM
abline(h=median(as.matrix(logcounts)), col="blue")
```

> ### Challenge 1
>
> 1. Use the `DESeq2` function `rlog` to transform the count data. This function
> also normalises for library size.
> 2. Plot the count distribution boxplots with this data
> How has this effected the count distributions?

```{r solutionChallenge1}
rlogcounts <- rlog(countdata)

statusCol <- as.numeric(factor(sampleinfo$Status)) + 1
# Check distributions of samples using boxplots
boxplot(rlogcounts, 
        xlab="", 
        ylab="Log2(Counts)",
        las=2,
        col=statusCol)
# Let's add a blue horizontal line that corresponds to the median logCPM
abline(h=median(as.matrix(logcounts)), col="blue")
```


## Principle Component Analysis

```{r pcaPlot, message = FALSE, fig.width=6.5, fig.height=5, fig.align="center"}
library(ggfortify)

rlogcounts <- rlog(countdata)

# run PCA
pcDat <- prcomp(t(rlogcounts))
# plot PCA
autoplot(pcDat)
# Lets add colour to look at the clustering for Status
autoplot(pcDat,
         data = sampleinfo, 
         colour="Status", 
         size=5)
# and now status
# Lets add colour to look at the clustering for Cell Type
autoplot(pcDat,
         data = sampleinfo, 
         colour="CellType", 
         size=5)
# We could use shape for one of the factors
autoplot(pcDat,
         data = sampleinfo, 
         colour="Status", 
         shape="CellType",
         size=5)
# Specify some clearer shapes to use that have a black outline and use fill
autoplot(pcDat,
         data = sampleinfo, 
         fill="Status", 
         shape="CellType",
         size=5) +
    scale_shape_manual(values=c(21, 24)) +
    guides(fill = guide_legend(override.aes=list(shape=22)))
```

> ### Discussion
>
> Look at the last PCA plot.
> What is the greatest source of variation?
> Is there something strange going on with the samples?
> Let's identify these samples:

```{r badSamples, fig.width=6.5, fig.height=5, fig.align="center"}
# setting shape to FALSE causes the plot to default to using the labels
autoplot(pcDat,
         data = sampleinfo, 
         colour="CellType", 
         shape=FALSE,
         label.size=6)
```

**MCL1.DG** is labelled **luminal** but should be **basal**
**MCL1.LA** is labelled **basal**   but should be **luminal**


```{r correctSampleSheet}
sampleinfo <- sampleinfo %>% 
    mutate(CellType=ifelse(Sample=="MCL1.DG", "basal", CellType)) %>% 
    mutate(CellType=ifelse(Sample=="MCL1.LA", "luminal", CellType)) %>% 
    mutate(Group=str_c(CellType, ".", Group))
```

```{r, exportSampleSheet, eval=FALSE}
write_csv(sampleinfo, "results/SampleInfo_Corrected.txt")
```

Fixed PCA:

```{r correctedPCA, fig.width=6.5, fig.height=5, fig.align="center"}
autoplot(pcDat,
         data = sampleinfo, 
         fill="Status", 
         shape="CellType",
         size=5) +
    scale_shape_manual(values=c(21, 24)) +
    guides(fill = guide_legend(override.aes=list(shape=22)))
```

> ### Discussion
>
> What is the greatest source of variation in the data (i.e. what does dimension 1 represent)?
> What is the second greatest source of variation in the data?
>

PCA:

* **Potential sample swaps**
* **Batch effects**

## **skip** PCA beyond the first two dimensions 

```{r plotPCA3and4, fig.width=6.5, fig.height=5, fig.align="center"}
autoplot(pcDat,
         data = sampleinfo, 
         fill = "Status", 
         shape = "CellType",
         size = 5,
         x = 2,
         y = 3) +
    scale_shape_manual(values=c(21, 24)) +
    guides(fill = guide_legend(override.aes=list(shape=22)))
```

## **skip** Interactive MDS Plot with Glimma

Another alternative is to generate a Multidimensional scaling (MDS) plot. MDS 
is similar to PCA, in MDS the distance between each pair of samples in the MDS
plot is calculated as the 'leading fold change', which is defined as the
root-mean-square of the largest 500 log2-fold changes between that pair of
samples. The *Glimma* package creates interactive plots that allow the use to 
explore the different dimensions.

```{r glimmaMDS, eval=FALSE}
library(Glimma)
glMDSPlot(rlogcounts, 
          labels = sampleinfo$Sample, 
          groups = sampleinfo[,c("CellType", "Status")], 
          folder = "mds")
```

*Glimma* was created to make interactive versions of some of the popular plots
from the *limma* package. At present it can be used to obtain MDS plots. The
output of `glMDSPlot` is an html page (/mds/MDS-Plot.html) that shows the MDS
plot on the left, and the amount of variation explained by each dimension in a
barplot on the right. The user can hover over points to find out sample
information, and switch between successive dimensions in the MDS plot by 
clicking on the bars in the barplot. The default MDS plots shows dimensions 1 
and 2.

## Hierarchical clustering with heatmaps

An alternative to PCA plots for examining relationships between samples is
using hierarchical clustering. Heatmaps are a nice visualisation to examine
hierarchical clustering of your samples. We can do this using the `heatmap.2`
function from the *gplots* package. In this example `heatmap.2` calculates a
matrix of euclidean distances from the `logcounts` object.

The *RColorBrewer* package has nicer colour schemes, accessed using the
`brewer.pal` function. "RdYlBu" is a common choice, and "Spectral" is also
nice.

Note:The `png` function will create a png file to save the plots created
straight after, and will close this file when `dev.off()` is called. To see
your plots interactively, simply omit those two lines.

We don't want to plot a heatmap of all 22013 genes, so let's select data for the 
500 most variable genes and plot the heatmap.

```{r getHMData}
# We estimate the variance for each row in the logcounts matrix
countVar <- apply(rlogcounts, 1, var)
# Get the row numbers for the top 500 most variable genes
highVar <- order(countVar, decreasing=TRUE)[1:500]
# Subset logcounts matrix
hmDat <- rlogcounts[highVar,]
```

```{r plotHM, fig.width=10, fig.height=10, message = FALSE}
library(gplots)
library(RColorBrewer)

# Get some nicer colours
mypalette <- brewer.pal(11, "RdYlBu")
# http://colorbrewer2.org/#type=sequential&scheme=BuGn&n=3
morecols <- colorRampPalette(mypalette)
# Set up colour vector for celltype variable
col.cell <- c("purple","orange")[sampleinfo$CellType]

# Plot the heatmap
heatmap.2(hmDat, 
          col=rev(morecols(50)),
          trace="column", 
          main="Top 500 most variable genes across samples",
          ColSideColors=col.cell,scale="row")
```

> ### **skip** Challenge 2  {.challenge}
>
> Redo the heatmap using the top 500 LEAST variable genes.  
> Change the colour scheme to "PiYG" and redo the heatmap. Try `brewer.pal.info` 
> and `display.brewer.all` to see what other colour schemes are available.  
> Change the sample names to `group` using the `labCol` argument  
> Remove the gene names from the righthand side of the plot using `labRow`  

```{r solutionChallenge2, fig.height=15, fig.width=10}

# Get the gene names for the top 500 least variable genes
lowVar <- order(countVar)[1:500]
# Subset logcounts matrix
hmData <- rlogcounts[lowVar,]

## Get some nicer colours
mypalette <- brewer.pal(11,"PiYG")
## http://colorbrewer2.org/#type=sequential&scheme=BuGn&n=3
morecols <- colorRampPalette(mypalette)
# Set up colour vector for celltype variable
col.cell <- c("purple","orange")[sampleinfo$CellType]

# Plot the heatmap
heatmap.2(hmData, 
          col=rev(morecols(50)),
          trace="none", 
          main="Top 500 most variable genes across samples",
          ColSideColors=col.cell,scale="row",
          labCol=sampleinfo$Group, 
          labRow = NA)

```


-----


# Convert counts to **DESeqDataSet** object

we need to provide:
* counts
* sample information
* a design formula

```{r makeDDSObj}
# first lets check that our rows and columns match
all(sampleinfo$Sample == colnames(countdata))
# create the design formula
design <- as.formula(~ CellType)
# create the DESeqDataSet object
ddsObj <- DESeqDataSetFromMatrix(countData = countdata,
                              colData = sampleinfo,
                              design = design)
```

## Normalisation

```{r estimateSizeFactors}
# Apply normalisation to DDS object
ddsObj <- estimateSizeFactors(ddsObj)
```

Take a look at the normalisation factors for these samples.

```{r vizNormFactors}
ddsObj@colData$sizeFactor
```

MCL1.LA and MCL1.LE have extreme sizeFactors - let's visualize the data to see
what the normalisation does to it

## MA plots - raw

```{r plotRawMA, fig.height=5, fig.width=10, message = FALSE}
library(limma)
logcounts <- log2(countdata + 1)

par(mfrow=c(1,2))
plotMA(logcounts, array = 7)
abline(h=0,col="grey")
plotMA(logcounts, array = 11)
abline(h=0,col="grey")
```

## MA plots - normalised

```{r plotNormedMA, fig.height=5, fig.width=10}
normalizedCounts <- counts(ddsObj, normalized=TRUE) 
logNormalizedCounts <- log2(normalizedCounts + 1)

par(mfrow=c(1,2))
plotMA(logNormalizedCounts, array = 7)
abline(h=0,col="grey")
plotMA(logNormalizedCounts, array = 11)
abline(h=0,col="grey")
```

> ### Challenge 3
>
> Plot the biased and unbiased MA plots both samples side by side to see the 
> before and after normalisation.
>

```{r solutionChallenge3, echo=FALSE, fig.height=10, fig.width=10}
par(mfrow=c(2,2))
plotMA(logcounts, array = 7, main="MCL1.LA - Raw")
abline(h=0,col="grey")
plotMA(logNormalizedCounts, array = 7, main="MCL1.LA - Normalised")
abline(h=0,col="grey")
plotMA(logcounts, array = 11, main="MCL1.LE - Raw")
abline(h=0,col="grey")
plotMA(logNormalizedCounts, array = 11, main="MCL1.LE - Normalised")
abline(h=0,col="grey")
```

## Export data

**We can save a few data objects to use later so we don't have to rerun 
everything**

```{r saveData, eval=F}
save(countdata, sampleinfo, file="results/preprocessing.RData")
```
